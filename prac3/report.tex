\documentclass[conference]{IEEEtran}
\usepackage{graphicx}
\graphicspath{ {images} }
\usepackage{hyperref}
\usepackage{biblatex}
\addbibresource{reference.bib}

\title{Infection Area Segmentation on X-ray Images}
\author{Phan Thanh BÃ¬nh BI12-059}

\begin{document}
\maketitle

\section{Introduction}
X-ray refers to the electromagnetic sound wave which has the wavelengths ranging from $10pm$ to $10nm$. This technology works based on the tissue differential contrast generated by X-ray and tissue interaction. Using X-ray for diagnostics is an extremely essential tool in modern medicine. One of the applications of X-ray is in medical imaging. X-ray is generated by bombarding a metal target with energetic electrons. Upon impact with the metal target, the incident electrons collide with the electrons and nuclei of the metal atoms. The collisions slow down and deflect the incident electrons. The rapid increase in the momentum of the incident electrons produce large acceleration values and deflected incident electrons emit X-rays. The generated X-rays are then passed through the patient's body and is recorded by the 2D sensor. X-ray image is finally produced with the usage of projection radiography.

COVID-19 is a highly infectious lung disease caused by the corona virus. It was first identified in Wuhan, China, and rapidly spread worldwide, leading to a global pandemic. COVID-19 can cause a wide range of symptoms, from mild flu-like symptoms to severe respiratory distress and death, particularly in older adults and those with declined health conditions. Moreover, the disease can be easily spread through droplets when infected people cough, sneeze, talks or by touching contaminated surfaces. Thus it is vital to isolate infected people as quickly as possible in order to reduce the chance of diffusing the disease unintentionally. One of many ways to achieve this is by distinguishing X-ray lung image of infected versus normal person. In this work, we will:
\begin{itemize}
    \item Explore the \href{https://www.kaggle.com/datasets/anasmohammedtahir/covidqu}{COVID-QU-Ex Dataset}
    \item Build a deep learning model to perform segmentation of the infection area from the input lung image.
\end{itemize}

\section{Dataset}
This dataset contains 2 sub datasets: \emph{Infection Segmentation} and \emph{Lung Segmentation} data. The files structure can be view in figure \ref{fig:struct}. To summarize, both sub datasets contains \emph{train-val-test} splits each split with chest images and ground truth lung segmentation map for 3 types of patients: COVID, non-COVID(other diseases), normal. However, only the \emph{Infection Segmentation} provide the infected area map, that is why for our work, we focus on this sub dataset. Figure \ref{fig:vis} shows examples of the \emph{Infection Segmentation} dataset. One key note is that the infected map segmentation for both the non-COVID and normal patients are filled with \emph{zeros}. The statistics about the number of images are shown in table \ref{tab:stats}. Fortunately, the number of positive and negative samples are equal.
\begin{figure}
    \centering
    \includegraphics[width=0.3\textwidth]{struct.png}
    \caption{Files Structure}
    \label{fig:struct}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=0.4\textwidth]{xray.png}
    \includegraphics[width=0.4\textwidth]{lung.png}
    \includegraphics[width=0.4\textwidth]{infect.png}
    \caption{Dataset visualizations}
    \label{fig:vis}
\end{figure}

\begin{table}
\centering
\begin{tabular}{ |c|c|c|c| } 
 \hline
 & Train & Val & Test \\ 
 \hline
 COVID & 1864 & 466 & 583 \\ 
 Non-COVID & 932 & 233 & 292 \\ 
 Normal & 932 & 233 & 291 \\ 
 \hline
\end{tabular}

\caption{Number of images statistics}
\label{tab:stats}
\end{table}

\section{Method}
\subsection{Architecture}
Our task is quite straightforward: given a chest X-ray image, we want to have a segmentation of the infected area. For that reason, we utilize the architecture design similar to U-Net\cite{Ronneberger2015}. We changes the input image size to 256x256 and only perform 3 times up/down sampling. The details can be viewed in figure \ref{fig:unet}. This architecture follows the \emph{encoder-decoder} scheme to obtain the segmentation map. The features extractor mechanisms is done by two convolutional layers combine with one maxpool layer similar to VGG \cite{Simonyan2015}. The concatenation of features used in upsampling phase before continue  performing convolution works as a method to avoid vanishing gradients problem.
\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{unet.pdf}
    \caption{Model architecture}
    \label{fig:unet}
\end{figure*}

\subsection{Training}
We train the model on the train and val splits and validate on the test split. 
The model is trained on $10$ epochs with \emph{binary cross entropy loss}, using \emph{Adam optimizer} with \emph{learning rate} $0.0001$ and \emph{batch size} $16$.

\section{Evaluation}
This step is the evaluation of the segmentation model. The metric we use is the average of \emph{Root Mean Squared Error (RMSE)}. \emph{RMSE} metric simply determines how well the model's prediction similar to the ground truth segmented map by calculating the distance between the prediction and the ground truth. \[RMSE=\frac{1}{N}\sum_{i=1}^{N}\sqrt{(x_p - x_t)^2}\] \emph{where} $x_p$ is the prediction $x_t$ is the ground truth. Our model achieve the score of \textbf{0.0695}.

\section{Conclusion}
In this work, we have examine the dataset from \href{https://www.kaggle.com/datasets/anasmohammedtahir/covidqu}{COVID-QU-Ex Dataset}. However, due to the inconsistency of our proposed formula with the ground truth annotations, we can only evaluate on the segmentation task in our pipeline.

\printbibliography
\end{document}